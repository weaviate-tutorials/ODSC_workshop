{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "AI_STUDIO_KEY = os.getenv(\"GOOGLE_AI_STUDIO_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "\n",
    "# Connect to the local instance deployed with Docker Compose\n",
    "client = weaviate.connect_to_local(\n",
    "    headers={\n",
    "       \"X-Google-Api-Key\": AI_STUDIO_KEY,\n",
    "    }\n",
    ")\n",
    "\n",
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import weaviate, os\n",
    "\n",
    "# client = weaviate.connect_to_wcs(\n",
    "#     cluster_url=os.getenv(\"WORKSHOP_DEMO_URL\"),\n",
    "#     auth_credentials=weaviate.auth.AuthApiKey(os.getenv(\"WORKSHOP_DEMO_KEY_ADMIN\")),\n",
    "#     headers={\n",
    "#        \"X-Palm-Api-Key\": AI_STUDIO_KEY,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# client.is_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data from arxiv\n",
    "\n",
    "1. Get chunks from paper - `get_chunks_from_paper`\n",
    "2. Create a tenant for the paper - `create_tenant`\n",
    "3. Batch import chunks - `batch_import_chunks`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get chunks from paper - `get_chunks_from_paper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distyll.text import from_arxiv_paper\n",
    "from distyll.utils import chunk_text\n",
    "\n",
    "def get_chunks_from_paper(url):\n",
    "    paper = from_arxiv_paper(url)\n",
    "    chunks = chunk_text(source_text=paper[\"text\"])\n",
    "\n",
    "    paper[\"arxiv_id\"] = url.replace(\"https://arxiv.org/pdf/\", \"\").replace(\".pdf\", \"\").replace(\".\", \"-\")\n",
    "    paper[\"chunks\"] = chunks\n",
    "    return paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_2212 = get_chunks_from_paper(\"https://arxiv.org/pdf/2212.10496.pdf\")\n",
    "chunked_2212"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Batch import chunks - `batch_import_chunks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = client.collections.get(\"Papers\")\n",
    "\n",
    "def batch_import_chunks(chunked_paper):\n",
    "\n",
    "    i=0\n",
    "    with papers.batch.rate_limit(100) as batch:\n",
    "        for chunk in chunked_paper[\"chunks\"]:\n",
    "            batch.add_object({\n",
    "                \"arxiv_id\": chunked_paper[\"arxiv_id\"],\n",
    "                \"title\": chunked_paper[\"title\"],\n",
    "                \"url\": chunked_paper[\"url\"],\n",
    "                \"chunk\": chunk,\n",
    "                \"chunk_no\": i,\n",
    "            })\n",
    "            i+=1\n",
    "\n",
    "    if(len(papers.batch.failed_objects)>0):\n",
    "        print(\"Import complete with errors\")\n",
    "        for err in papers.batch.failed_objects:\n",
    "            print(err)\n",
    "    else:\n",
    "        print(\"Import complete with no errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_import_chunks(chunked_2212)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end paper load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_paper(url):\n",
    "    cp = get_chunks_from_paper(url)\n",
    "    batch_import_chunks(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_paper(\"https://arxiv.org/pdf/2401.00107.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers.aggregate.over_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close the client when done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
