{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal Scenario\n",
    "\n",
    "### Vectorize images with Vertex AI\n",
    "If you have a project configured with Vertex AI, you can use `multimodalembedding@001` - a multimodal model that can vectorize text, images and video.\n",
    "\n",
    "### Vectorize images with CLIP\n",
    "Otherwise, you can use a CLIP model.<br/>\n",
    "CLIP can only be used with a local deployment using Docker Compose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "AI_STUDIO_KEY = os.getenv(\"GOOGLE_AI_STUDIO_KEY\")\n",
    "\n",
    "VERTEX_AI_KEY = os.getenv(\"GOOGLE_VERTEX_AI_KEY\")\n",
    "VERTEX_AI_PROJECT = os.getenv(\"GOOGLE_VERTEX_AI_PROJECT\")\n",
    "\n",
    "if(VERTEX_AI_KEY == None):\n",
    "    print(\"VERTEX_AI_KEY is missing. Follow the CLIP path for this exercise.\")\n",
    "    print(\"Or configure a Google Vertex AI account with  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERTEX_AI_KEY = \"ya29.a0AXooCgskulIrPZyuV...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect with Vertex AI key\n",
    "If you have a project configured with Vertex AI, you can use `multimodalembedding@001` - a multimodal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate, os\n",
    "\n",
    "# Connect to the local instance deployed with Docker Compose\n",
    "client = weaviate.connect_to_local(\n",
    "    headers={\n",
    "        # \"X-Google-Vertex-Api-Key\": VERTEX_AI_KEY,\n",
    "        \"X-Google-Api-Key\": VERTEX_AI_KEY,\n",
    "        \"X-Google-Studio-Api-Key\": AI_STUDIO_KEY,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Connect to a Weaviate Cloud instance - needs 1.24.14 or newer // 1.25.1 or newer\n",
    "# client = weaviate.connect_to_wcs(\n",
    "#     cluster_url=os.getenv(\"WORKSHOP_DEMO_URL\"),\n",
    "#     auth_credentials=weaviate.auth.AuthApiKey(os.getenv(\"WORKSHOP_DEMO_KEY_ADMIN\")),\n",
    "\n",
    "#     headers={\n",
    "#         \"X-Google-Api-Key\": VERTEX_AI_KEY,\n",
    "#         \"X-Google-Studio-Api-Key\": AI_STUDIO_KEY,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect with CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "\n",
    "# Connect to the local instance deployed with Docker Compose\n",
    "client = weaviate.connect_to_local(\n",
    "    headers={\n",
    "        \"X-Google-Studio-Api-Key\": AI_STUDIO_KEY,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Configure, Property, DataType, Multi2VecField\n",
    "\n",
    "client.collections.delete(\"MoviesMM\")\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"MoviesMM\",  # The name of the collection ('NV' for named vectors)\n",
    "    properties=[ # optional\n",
    "        Property(name=\"title\", data_type=DataType.TEXT),\n",
    "        Property(name=\"overview\", data_type=DataType.TEXT),\n",
    "        Property(name=\"rating\", data_type=DataType.NUMBER),\n",
    "        Property(name=\"release_date\", data_type=DataType.DATE),\n",
    "        Property(name=\"tmdb_id\", data_type=DataType.INT),\n",
    "        Property(name=\"poster_url\", data_type=DataType.TEXT),\n",
    "        Property(name=\"poster\", data_type=DataType.BLOB),\n",
    "    ],\n",
    "\n",
    "    # Define & configure the vectorizer module\n",
    "    vectorizer_config=[\n",
    "        # Vectorize the movie title and summary\n",
    "        Configure.NamedVectors.text2vec_palm(\n",
    "            name=\"content\",\n",
    "            source_properties=[\"title\", \"overview\"],\n",
    "\n",
    "            model_id=\"text-embedding-004\",\n",
    "            api_endpoint=\"generativelanguage.googleapis.com\",\n",
    "            project_id=\"devrel-projects\",\n",
    "        ),\n",
    "\n",
    "        # Vectorize the movie poster (image)\n",
    "        Configure.NamedVectors.multi2vec_clip(\n",
    "            name=\"poster\",\n",
    "            image_fields=[\"poster\"]\n",
    "            # image_fields=[\n",
    "            #     Multi2VecField(name=\"poster\", weight=0.9)\n",
    "            # ],\n",
    "            # text_fields=[\n",
    "            #     Multi2VecField(name=\"title\", weight=0.1)\n",
    "            # ],\n",
    "        )\n",
    "\n",
    "        # Configure.NamedVectors.multi2vec_palm(\n",
    "        #     name=\"poster\",\n",
    "        #     image_fields=[\"poster\"],\n",
    "        #     text_fields=[\"title\"],\n",
    "        #     location=\"us-central1\",\n",
    "        #     model_id=\"multimodalembedding@001\",\n",
    "        #     project_id=\"devrel-projects\"\n",
    "        # )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_json(\"./data/movies_data_1990_2024.json\")\n",
    "df = pd.read_json(\"./data/movies_data_small.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of loading images from the Internet\n",
    "> We won't use it for import for this project, as that could get flagged by tmdb servers as an attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64, requests\n",
    "\n",
    "def url_to_base64(url):\n",
    "    image_response = requests.get(url)\n",
    "    content = image_response.content\n",
    "    return base64.b64encode(content).decode(\"utf-8\")\n",
    "\n",
    "url_to_base64(\"https://image.tmdb.org/t/p/w600_and_h900_bestv2/1RFIbuW9Z3eN9Oxw2KaQG5DfLmD.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "# test top 3 items\n",
    "for i, movie in enumerate(df.head(3).itertuples(index=False)):\n",
    "    poster_path = f\"https://image.tmdb.org/t/p/w600_and_h900_bestv2{movie.poster_path}\"\n",
    "    poster = url_to_base64(poster_path)\n",
    "\n",
    "    print(movie.title)\n",
    "    print(poster_path)\n",
    "    print(poster, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load poster images from a local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# Helper function to convert a file to base64 representation\n",
    "def toBase64(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        return base64.b64encode(file.read()).decode('utf-8')\n",
    "    \n",
    "toBase64(\"./posters/162_poster.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "# test top 3 items\n",
    "for i, movie in enumerate(df.head(3).itertuples(index=False)):\n",
    "    poster_path = f\"https://image.tmdb.org/t/p/w600_and_h900_bestv2{movie.poster_path}\"\n",
    "    posterb64 = toBase64(f\"./posters/{movie.id}_poster.jpg\")\n",
    "\n",
    "    print(movie.title)\n",
    "    print(poster_path)\n",
    "    print(posterb64, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert with Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "from weaviate.util import generate_uuid5\n",
    "\n",
    "movies = client.collections.get(\"MoviesMM\")\n",
    "with movies.batch.rate_limit(100) as batch:\n",
    "\n",
    "    for i, movie in enumerate(df.itertuples(index=False)):\n",
    "        if(i == 200): # load the first 200 movie objects\n",
    "            break\n",
    "\n",
    "        print(i, movie.title)\n",
    "\n",
    "        # Convert a JSON date to `datetime` and add time zone information\n",
    "        release_date = datetime.strptime(movie.release_date, \"%Y-%m-%d\").replace(\n",
    "            tzinfo=timezone.utc\n",
    "        )\n",
    "\n",
    "        poster_path = f\"https://image.tmdb.org/t/p/w600_and_h900_bestv2{movie.poster_path}\"\n",
    "        posterb64 = toBase64(f\"./posters/{movie.id}_poster.jpg\")\n",
    "\n",
    "        movie_obj = {\n",
    "            \"title\": movie.title,\n",
    "            \"overview\": movie.overview,\n",
    "            \"rating\": movie.vote_average,\n",
    "            \"release_date\": release_date,\n",
    "            \"tmdb_id\": movie.id, # https://www.themoviedb.org/movie/{tmdb_id}\n",
    "            \"poster_path\": poster_path,\n",
    "            \"poster\": posterb64\n",
    "        }\n",
    "\n",
    "        batch.add_object(\n",
    "            properties=movie_obj,\n",
    "            uuid=generate_uuid5(movie.id)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for batch errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for failed objects\n",
    "if len(movies.batch.failed_objects) > 0:\n",
    "    print(f\"Failed to import {len(movies.batch.failed_objects)} objects\")\n",
    "    for failed in movies.batch.failed_objects:\n",
    "        print(f\"e.g. Failed to import object with error: {failed.message}\")\n",
    "else:\n",
    "    print(\"No errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.aggregate.over_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
